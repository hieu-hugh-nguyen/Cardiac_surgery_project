{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyreadr\n",
    "# %pip install catboost\n",
    "# %pip install lckr-jupyterlab-variableinspector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import os, sys\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/home/idies/workspace/Storage/hnguye78/persistent/cv_surgery'\n",
    "exec(open(work_dir+'/code/Python/snippets/helpful_functions.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'sts_mort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = work_dir+'/csv_files/pre_anat_intra'\n",
    "feature_space = pd.read_csv(load_dir+'/feature_space_preop_anat_intra_w_interaction_terms.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = feature_space.rename(columns={\"feature_space.concatid\": \"concatid\"}).drop(['Unnamed: 0'], axis =1)\n",
    "feature_space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#label_space = pd.read_csv(smb2.open('//'+work_dir+'/label_space_sts.csv'))\n",
    "label_space = pd.read_csv(load_dir+'/label_space.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_space_no_na = label_space.fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_space_no_na[['concatid', outcome]].drop_duplicates(subset='concatid', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(label_df, feature_space.drop_duplicates(subset='concatid', keep=\"last\")\n",
    "                , how='left', on='concatid', left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data\n",
    "data = data_full.drop(['concatid'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = list(feature_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={outcome: 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label: 2 (alive) to 0 (class 0)\n",
    "data.loc[data.label ==2, 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train set/test set in stratified fashion, then downsample training set to balance outcome class:\n",
    "from sklearn import model_selection\n",
    "outercv = sklearn.model_selection.StratifiedKFold(n_splits=10,shuffle=True,random_state= 1)\n",
    "X = data.drop(['label'],axis =1).values\n",
    "y = data[['label']].values\n",
    "\n",
    "for train_index, test_index in outercv.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "train_df = data.iloc[train_index]\n",
    "test_df = data.iloc[test_index]\n",
    "train_df_majority = train_df[train_df['label']==0]\n",
    "train_df_minority = train_df[train_df['label']==1]\n",
    "\n",
    "# Downsampling:\n",
    "from sklearn.utils import resample\n",
    "train_df_majority_downsampled = resample(train_df_majority, \n",
    "                                 replace=False,     # sample without replacement\n",
    "                                 n_samples=2*train_df_minority.shape[0],    # to match minority class\n",
    "                                 random_state=1)\n",
    "\n",
    "df_downsampled = pd.concat([train_df_majority_downsampled, train_df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test: 1 = dead, 2 = live. Convert live to class 0:\n",
    "\n",
    "import numpy as np\n",
    "np.array(np.unique(y_test, return_counts=True)).T\n",
    "y_test[y_test == 2] = 0\n",
    "y_train[y_train == 2] = 0\n",
    "np.array(np.unique(y_test, return_counts=True)).T\n",
    "\n",
    "hide_toggle(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set further to cv_train-validation set, using stratified k-fold cv: 10-fold x 5 times\n",
    "# train and calibrate models\n",
    "hide_toggle()\n",
    "from sklearn import model_selection\n",
    "outercv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=5, n_repeats = 2,random_state= 1)\n",
    "\n",
    "# initialize:\n",
    "cv_performance_df = pd.DataFrame()\n",
    "cv_performance_isotonic_df = pd.DataFrame()\n",
    "cv_performance_sigmoid_df = pd.DataFrame()\n",
    "training_bs_testset_pred_df = data_full[['concatid',outcome]].loc[test_index,:].rename(columns={outcome: 'label'})\n",
    "training_bs_testset_pred_calibrated_isotonic_df = training_bs_testset_pred_df.copy(deep = True)\n",
    "training_bs_testset_pred_calibrated_sigmoid_df = training_bs_testset_pred_df.copy(deep = True)\n",
    "\n",
    "fold = 1\n",
    "for cv_train_index, cv_test_index in outercv.split(X_train, y_train):\n",
    "    print(\"Fold \"+ str(fold) + \"....\")\n",
    "    fold = fold + 1\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    cv_X_train, cv_X_test = X_train[cv_train_index], X_train[cv_test_index]\n",
    "    cv_y_train, cv_y_test = y_train[cv_train_index], y_train[cv_test_index]\n",
    "    \n",
    "    cv_train_df = data.iloc[cv_train_index]\n",
    "    cv_test_df = data.iloc[cv_test_index]\n",
    "    cv_train_df_majority = cv_train_df[cv_train_df['label']==0]\n",
    "    cv_train_df_minority = cv_train_df[cv_train_df['label']==1]\n",
    "\n",
    "    # Downsampling:\n",
    "    from sklearn.utils import resample\n",
    "    cv_train_df_majority_downsampled = resample(cv_train_df_majority, \n",
    "                                     replace=False,     # sample without replacement\n",
    "                                     n_samples=2*cv_train_df_minority.shape[0],    # to match minority class\n",
    "                                     random_state=1)\n",
    "\n",
    "    # Combine downsampled majority class with minority class\n",
    "    cv_df_downsampled = pd.concat([cv_train_df_majority_downsampled, cv_train_df_minority])\n",
    "    cv_X_train_downsampled = cv_df_downsampled.drop(['label'],axis =1)\n",
    "    cv_y_train_downsampled = cv_df_downsampled['label'].ravel()\n",
    "    \n",
    "    \n",
    "    # Train model:\n",
    "    from catboost import CatBoostClassifier\n",
    "    cv_cb_downsampled =  CatBoostClassifier(random_state = 1)\n",
    "    cv_cb_downsampled.fit(cv_X_train_downsampled, cv_y_train_downsampled, verbose = False)\n",
    "\n",
    "    \n",
    "    # Evaluate model on cv_test_set (validation set):\n",
    "    cv_y_test_predict_proba_cb_downsampled = cv_cb_downsampled.predict_proba(cv_X_test)[:, 1]\n",
    "    performance_metrics = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled, thres = 0.5)\n",
    "    cv_performance_df = cv_performance_df.append(performance_metrics, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Pred prob of model on holdout testset:\n",
    "    training_bs_testset_pred_df['time_'+str(fold-1)] = cv_cb_downsampled.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # calibrate model, record performance metric validation set, and pred prob on holdout testset:\n",
    "    cv_cb_downsampled_isotonic_on_cv = calibrate_model(cv_cb_downsampled, cv_X_train, cv_y_train.ravel(), method = 'isotonic')\n",
    "    training_bs_testset_pred_calibrated_isotonic_df['time_'+str(fold-1)] = cv_cb_downsampled_isotonic_on_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cv_y_test_predict_proba_cb_downsampled_isotonic = cv_cb_downsampled_isotonic_on_cv.predict_proba(cv_X_test)[:, 1]\n",
    "    performance_metrics_isotonic = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled_isotonic, thres = 0.5)\n",
    "    cv_performance_isotonic_df = cv_performance_isotonic_df.append(performance_metrics_isotonic, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    cv_cb_downsampled_sigmoid_on_cv = calibrate_model(cv_cb_downsampled, cv_X_train, cv_y_train.ravel(), method = 'sigmoid')\n",
    "    training_bs_testset_pred_calibrated_sigmoid_df['time_'+str(fold-1)] = cv_cb_downsampled_sigmoid_on_cv.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    cv_y_test_predict_proba_cb_downsampled_sigmoid = cv_cb_downsampled_sigmoid_on_cv.predict_proba(cv_X_test)[:, 1]\n",
    "    performance_metrics_sigmoid = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled_sigmoid, thres = 0.5)\n",
    "    cv_performance_sigmoid_df = cv_performance_sigmoid_df.append(performance_metrics_sigmoid, ignore_index=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bs_testset_pred_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_' + outcome +'.csv', index=False)\n",
    "training_bs_testset_pred_calibrated_isotonic_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_isotonic_on_cv_' + outcome +'.csv', index=False)\n",
    "training_bs_testset_pred_calibrated_sigmoid_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_sigmoid_on_cv_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_performance_df.to_csv(load_dir+'/'+'cv_performance_df_' + outcome +'.csv', index=False)\n",
    "cv_performance_df.describe(percentiles = [.025, .5, .975]).round(decimals = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_cv_performance = pd.DataFrame(cv_performance_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "\n",
    "print_cv_performance.to_csv(load_dir+'/'+'print_cv_performance_' + outcome +'.csv', index=False)\n",
    "print_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_performance_isotonic_df.to_csv(load_dir+'/'+'cv_performance_isotonic_df_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_isotonic = pd.DataFrame(cv_performance_isotonic_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_cv_performance_isotonic.to_csv(load_dir+'/'+'print_cv_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_performance_sigmoid_df.to_csv(load_dir+'/'+'cv_performance_sigmoid_df_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_sigmoid = pd.DataFrame(cv_performance_sigmoid_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_cv_performance_sigmoid.to_csv(load_dir+'/'+'print_cv_performance_sigmoid_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models:\n",
    "import pickle\n",
    "pickle.dump(cv_cb_downsampled, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled.sav', 'wb'))\n",
    "pickle.dump(cv_cb_downsampled_isotonic_on_cv, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled_isotonic_calibration_on_cv.sav', 'wb'))\n",
    "pickle.dump(cv_cb_downsampled_sigmoid_on_cv, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled_isotonic_calibration_on_cv.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance:\n",
    "\n",
    "feature_imp_df = cv_cb_downsampled.get_feature_importance(prettified = True)\n",
    "feature_imp_df_sort = feature_imp_df.sort_values(by='Importances', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "feature_imp_df_sort.to_csv(load_dir+'/'+'feature_imp_df_sort_'+outcome+'.csv', index=False)\n",
    "\n",
    "decouple_var_imp_sort = decouple_var_imp(feature_imp_df_sort)\n",
    "decouple_var_imp_sort.to_csv(load_dir+'/'+'decouple_var_imp_sort_'+outcome+'.csv', index=False)\n",
    "decouple_var_imp_sort.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap testset:\n",
    "bs_testset_performance_df = pd.DataFrame()\n",
    "bs_testset_performance_isotonic_df = pd.DataFrame()\n",
    "bs_testset_performance_sigmoid_df = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "    bs_y_test = y_test[sample_indices]\n",
    "    bs_X_test = X_test[sample_indices,:]\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled = cv_cb_downsampled.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled, thres = 0.5)\n",
    "    bs_testset_performance_df = bs_testset_performance_df.append(bs_performance_metrics, ignore_index=True)\n",
    "\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled_isotonic = cv_cb_downsampled_isotonic_on_cv.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics_isotonic = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_isotonic, thres = 0.5)\n",
    "    bs_testset_performance_isotonic_df = bs_testset_performance_isotonic_df.append(bs_performance_metrics_isotonic, ignore_index=True)\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled_sigmoid = cv_cb_downsampled_sigmoid_on_cv.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics_sigmoid = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_sigmoid, thres = 0.5)\n",
    "    bs_testset_performance_sigmoid_df = bs_testset_performance_sigmoid_df.append(bs_performance_metrics_sigmoid, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_testset_performance_df.to_csv(load_dir+'/'+'bs_testset_performance_df_' + outcome +'.csv', index=False)\n",
    "bs_testset_performance_isotonic_df.to_csv(load_dir+'/'+'bs_testset_performance_isotonic_df_' + outcome +'.csv', index=False)\n",
    "bs_testset_performance_sigmoid_df.to_csv(load_dir+'/'+'bs_testset_performance_sigmoid_df_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_testset_performance_df.describe(percentiles = [.025, .5, .975]).round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance = pd.DataFrame(bs_testset_performance_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance.to_csv(load_dir+'/'+'print_bs_testset_performance_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance_isotonic = pd.DataFrame(bs_testset_performance_isotonic_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance_isotonic.to_csv(load_dir+'/'+'print_bs_testset_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance_isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance_sigmoid = pd.DataFrame(bs_testset_performance_sigmoid_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance_sigmoid.to_csv(load_dir+'/'+'print_bs_testset_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance figures:\n",
    "performance(bs_y_test, bs_y_test_predict_proba_cb_downsampled, thres = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as plt\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "# ax = feature_imp_df_sort.plot('Feature', 'Score', kind='bar', color='c')\n",
    "# ax.set_title(\"Feature Importance using Permutation method\", fontsize = 14)\n",
    "# ax.set_xlabel(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and calibrate model on entirety of the training set:\n",
    "\n",
    "# X_train_downsampled = df_downsampled.drop(['label'],axis =1)\n",
    "# y_train_downsampled = df_downsampled['label'].ravel()\n",
    "# from catboost import CatBoostClassifier\n",
    "# cb_downsampled =  CatBoostClassifier(random_state = 1)\n",
    "# cb_downsampled.fit(X_train_downsampled, y_train_downsampled, cat_features = np.array(get_cat_features(X_train_downsampled, 5)), verbose = False)\n",
    "# pickle.dump(cb_downsampled, open('model_' +outcome + '_cb_downsampled.sav', 'wb'))\n",
    "\n",
    "# # Create a corrected classifier. - Isotonic calibration\n",
    "# cb_downsampled_iso = sklearn.calibration.CalibratedClassifierCV(cb_downsampled, cv=10, method='isotonic')\n",
    "# cb_downsampled_iso.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "\n",
    "# pickle.dump(cb_downsampled_iso, open('model_' +outcome + '_cb_downsampled_iso.sav', 'wb'))\n",
    "\n",
    "# cb_downsampled_sigmoid = sklearn.calibration.CalibratedClassifierCV(cb_downsampled, cv=10, method='sigmoid')\n",
    "# cb_downsampled_sigmoid.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "# pickle.dump(cb_downsampled_sigmoid, open('model_' +outcome + '_cb_downsampled_sigmoid.sav', 'wb'))\n",
    "\n",
    "# # loaded_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "# # y_test_predict_proba_loaded_model = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # # Bootstrap testset:\n",
    "# # bs_testset_performance_df = pd.DataFrame()\n",
    "# # for i in range(10):\n",
    "# #     sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "# #     bs_y_test = y_test[sample_indices]\n",
    "# #     bs_X_test = X_test[sample_indices,:]\n",
    "# #     bs_y_test_predict_proba_cb_downsampled_iso = cb_downsampled_iso.predict_proba(bs_X_test)[:, 1]\n",
    "# #     bs_performance_metrics = performance(bs_y_test, bs_y_test_predict_proba_cb_downsampled_iso, thres = 0.5)\n",
    "# #     bs_testset_performance_df = bs_testset_performance_df.append(bs_performance_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bootstrap testset and spit prediction using calibrated model:\n",
    "# import pickle\n",
    "# import sklearn\n",
    "# iso_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "\n",
    "# bs_testset_pred_df = pd.DataFrame(list(zip(data_full['concatid'][test_index], test_index)),\n",
    "#                                 columns=['concatid', 'index'])\n",
    "# bs_testset_performance_iso_df = pd.DataFrame()\n",
    "# for i in range(10):\n",
    "#     sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "#     bs_y_test = y_test[sample_indices]\n",
    "#     bs_X_test = X_test[sample_indices,:]\n",
    "#     bs_y_test_predict_proba_cb_downsampled_iso = iso_model.predict_proba(bs_X_test)[:, 1]\n",
    "#     bs_performance_metrics = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_iso, thres = 0.5)\n",
    "#     bs_testset_performance_iso_df = bs_testset_performance_iso_df.append(bs_performance_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs_testset_performance_iso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled_iso = iso_model.predict_proba(X_test)[:, 1]\n",
    "# testset_iso_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled_iso)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_iso_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_iso_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_iso_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = before_iso_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_before_iso_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_sigmoid = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='sigmoid')\n",
    "# cv_cb_downsampled_sigmoid.fit(X_train, y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_sigmoid, open('model_' +outcome + '_cv_cb_downsampled_sigmoid.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_sigmoid_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_sigmoid.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_sigmoid_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_sigmoid_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# cv_cb_downsampled_isotonic.fit(X_train, y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic, open('model_' +outcome + '_cv_cb_downsampled_isotonic.sav', 'wb'))\n",
    "# cv_isotonic_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic_on_db = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# X_train_downsampled = df_downsampled.drop(['label'],axis =1)\n",
    "# y_train_downsampled = df_downsampled['label'].ravel()\n",
    "# cv_cb_downsampled_isotonic_on_db.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic_on_db, open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_db.sav', 'wb'))\n",
    "# cv_isotonic_model_on_db = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_db.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model_on_db.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_on_db_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic_on_cv = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# cv_cb_downsampled_isotonic_on_cv.fit(cv_X_train, cv_y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic_on_cv, open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_cv.sav', 'wb'))\n",
    "# cv_isotonic_model_on_cv = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_cv.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model_on_cv.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_on_cv_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout testset feature space and sts_pred_prob filter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testset_df = data_full.iloc[test_index,:]\n",
    "# testset_df.to_csv(load_dir+'/'+'testset_feature_df_' + outcome +'.csv', index=True)\n",
    "# # load sts pred prob and filter only patients in the holdout test set:\n",
    "# load_dir = '/home/idies/workspace/Storage/hnguye78/persistent'+'/csv_files'\n",
    "# sts_pred_prob_df = pd.read_csv(load_dir+'/sts_pred_prob.csv')\n",
    "# sts_pred_prob_df['concatid'] = sts_pred_prob_df['patid']+sts_pred_prob_df['recordid']\n",
    "# sts_pred_prob_df_rm_dups = sts_pred_prob_df.drop_duplicates(subset='concatid', keep=\"last\")\n",
    "# sts_pred_prob_testset = sts_pred_prob_df_rm_dups.loc[sts_pred_prob_df_rm_dups['concatid'].isin(testset_df['concatid']),['concatid', 'predvent']]\n",
    "\n",
    "# sts_pred_prob_testset.to_csv(load_dir+'/'+'sts_pred_prob_testset_' + outcome +'.csv', index=False)\n",
    "# # # check to make sure the concatid in sts_pred_prob and in the testset are the same: \n",
    "# print(sorted(list(sts_pred_prob_testset['concatid'])) == sorted(list(testset_df['concatid'])))\n",
    "# # # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Probability of Patients in Non-STS Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dir = '/home/idies/workspace/Storage/hnguye78/persistent'+'/csv_files'\n",
    "# feature_space_non_sts_patients = pd.read_csv(load_dir+'/non_sts_patients_feature_space.csv')\n",
    "# X_non_sts = feature_space_non_sts_patients.drop(['label','Unnamed: 0', 'concatid'], axis = 1).values\n",
    "# import pickle\n",
    "# import sklearn\n",
    "# loaded_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# y_non_sts_predict_proba = loaded_model.predict_proba(X_non_sts)[:, 1]\n",
    "\n",
    "# prob_risk_non_sts_df = pd.DataFrame(list(zip(feature_space_non_sts_patients['concatid'], y_non_sts_predict_proba)),\n",
    "#                                 columns=['concatid', 'predicted_prob'])\n",
    "# prob_risk_non_sts_df.to_csv(load_dir+'/'+'pred_prob_non_sts_patients_df_' + outcome +'.csv', index=False)\n",
    "# # # check to see that the non_sts set does not overlap with the testset concatid \n",
    "# # set((prob_risk_non_sts_df['concatid'])).intersection((set(testset_df['concatid'])))\n",
    "# # # no overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
