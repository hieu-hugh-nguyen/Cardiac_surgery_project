{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyreadr\n",
    "# %pip install catboost\n",
    "# %pip install lckr-jupyterlab-variableinspector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import os, sys\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import catboost\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/home/idies/workspace/Storage/hnguye78/persistent/cv_surgery'\n",
    "exec(open(work_dir+'/code/Python/snippets/helpful_functions.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'sts_14d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = work_dir+'/csv_files/pre_anat_intra'\n",
    "feature_space = pd.read_csv(load_dir+'/feature_space_preop_anat_intra_w_interaction_terms.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatid</th>\n",
       "      <th>proctype</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>raceasian</th>\n",
       "      <th>raceblack</th>\n",
       "      <th>racecaucasian</th>\n",
       "      <th>raceother</th>\n",
       "      <th>age</th>\n",
       "      <th>heightcm</th>\n",
       "      <th>...</th>\n",
       "      <th>nc_stern.cplegia_ant</th>\n",
       "      <th>nc_stern.cplegia_ret</th>\n",
       "      <th>nc_stern.frepl</th>\n",
       "      <th>nc_stern.inc_revasc</th>\n",
       "      <th>cplegia_ant.cplegia_ret</th>\n",
       "      <th>cplegia_ant.frepl</th>\n",
       "      <th>cplegia_ant.inc_revasc</th>\n",
       "      <th>cplegia_ret.frepl</th>\n",
       "      <th>cplegia_ret.inc_revasc</th>\n",
       "      <th>frepl.inc_revasc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10020V313492</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10022V3117559</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022V315180</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10031V313571</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>155.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10047V3420470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        concatid  proctype  gender  ethnicity  raceasian  raceblack  \\\n",
       "0   10020V313492         2       2          2          2          2   \n",
       "1  10022V3117559         2       1          2          2          2   \n",
       "2   10022V315180         6       2          2          2          2   \n",
       "3   10031V313571         1       2          2          2          2   \n",
       "4  10047V3420470         1       1          2          2          2   \n",
       "\n",
       "   racecaucasian  raceother   age  heightcm  ...  nc_stern.cplegia_ant  \\\n",
       "0              1          2  54.0     155.0  ...                     2   \n",
       "1              1          2  74.0     174.0  ...                     2   \n",
       "2              1          2  66.0     157.0  ...                     2   \n",
       "3              1          2  79.0     155.5  ...                     2   \n",
       "4              1          2  61.0     170.0  ...                     4   \n",
       "\n",
       "   nc_stern.cplegia_ret  nc_stern.frepl  nc_stern.inc_revasc  \\\n",
       "0                     2               4                    4   \n",
       "1                     4               4                    4   \n",
       "2                     2               4                    2   \n",
       "3                     2               4                    4   \n",
       "4                     4               4                    4   \n",
       "\n",
       "   cplegia_ant.cplegia_ret  cplegia_ant.frepl  cplegia_ant.inc_revasc  \\\n",
       "0                        1                  2                       2   \n",
       "1                        2                  2                       2   \n",
       "2                        1                  2                       1   \n",
       "3                        1                  2                       2   \n",
       "4                        4                  4                       4   \n",
       "\n",
       "   cplegia_ret.frepl  cplegia_ret.inc_revasc  frepl.inc_revasc  \n",
       "0                  2                       2                 4  \n",
       "1                  4                       4                 4  \n",
       "2                  2                       1                 2  \n",
       "3                  2                       2                 4  \n",
       "4                  4                       4                 4  \n",
       "\n",
       "[5 rows x 15755 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_space = feature_space.rename(columns={\"feature_space.concatid\": \"concatid\"}).drop(['Unnamed: 0'], axis =1)\n",
    "feature_space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#label_space = pd.read_csv(smb2.open('//'+work_dir+'/label_space_sts.csv'))\n",
    "label_space = pd.read_csv(load_dir+'/label_space.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_space_no_na = label_space.fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_space_no_na[['concatid', outcome]].drop_duplicates(subset='concatid', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatid</th>\n",
       "      <th>sts_14d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10020V313492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10022V3117559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022V315180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10031V313571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10047V3420470</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        concatid  sts_14d\n",
       "0   10020V313492        2\n",
       "1  10022V3117559        1\n",
       "2   10022V315180        2\n",
       "3   10031V313571        2\n",
       "4  10047V3420470        2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(label_df, feature_space.drop_duplicates(subset='concatid', keep=\"last\")\n",
    "                , how='left', on='concatid', left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data\n",
    "data = data_full.drop(['concatid'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sts_14d</th>\n",
       "      <th>proctype</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>raceasian</th>\n",
       "      <th>raceblack</th>\n",
       "      <th>racecaucasian</th>\n",
       "      <th>raceother</th>\n",
       "      <th>age</th>\n",
       "      <th>heightcm</th>\n",
       "      <th>...</th>\n",
       "      <th>nc_stern.cplegia_ant</th>\n",
       "      <th>nc_stern.cplegia_ret</th>\n",
       "      <th>nc_stern.frepl</th>\n",
       "      <th>nc_stern.inc_revasc</th>\n",
       "      <th>cplegia_ant.cplegia_ret</th>\n",
       "      <th>cplegia_ant.frepl</th>\n",
       "      <th>cplegia_ant.inc_revasc</th>\n",
       "      <th>cplegia_ret.frepl</th>\n",
       "      <th>cplegia_ret.inc_revasc</th>\n",
       "      <th>frepl.inc_revasc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>155.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34556</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>178.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34557</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34558</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34559</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34560</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34561 rows × 15755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sts_14d  proctype  gender  ethnicity  raceasian  raceblack  \\\n",
       "0            2         2       2          2          2          2   \n",
       "1            1         2       1          2          2          2   \n",
       "2            2         6       2          2          2          2   \n",
       "3            2         1       2          2          2          2   \n",
       "4            2         1       1          2          2          2   \n",
       "...        ...       ...     ...        ...        ...        ...   \n",
       "34556        1         7       1          2          2          2   \n",
       "34557        2         2       1          2          2          2   \n",
       "34558        2         2       1          2          2          2   \n",
       "34559        2         2       1          2          2          2   \n",
       "34560        2         2       1          2          2          2   \n",
       "\n",
       "       racecaucasian  raceother   age  heightcm  ...  nc_stern.cplegia_ant  \\\n",
       "0                  1          2  54.0     155.0  ...                     2   \n",
       "1                  1          2  74.0     174.0  ...                     2   \n",
       "2                  1          2  66.0     157.0  ...                     2   \n",
       "3                  1          2  79.0     155.5  ...                     2   \n",
       "4                  1          2  61.0     170.0  ...                     4   \n",
       "...              ...        ...   ...       ...  ...                   ...   \n",
       "34556              1          2  81.0     178.1  ...                     2   \n",
       "34557              1          2  66.0     191.0  ...                     2   \n",
       "34558              1          2  82.0     188.0  ...                     4   \n",
       "34559              1          2  55.0     185.0  ...                     2   \n",
       "34560              1          2  66.0     170.0  ...                     4   \n",
       "\n",
       "       nc_stern.cplegia_ret  nc_stern.frepl  nc_stern.inc_revasc  \\\n",
       "0                         2               4                    4   \n",
       "1                         4               4                    4   \n",
       "2                         2               4                    2   \n",
       "3                         2               4                    4   \n",
       "4                         4               4                    4   \n",
       "...                     ...             ...                  ...   \n",
       "34556                     4               4                    4   \n",
       "34557                     4               4                    4   \n",
       "34558                     4               4                    4   \n",
       "34559                     4               4                    4   \n",
       "34560                     4               4                    4   \n",
       "\n",
       "       cplegia_ant.cplegia_ret  cplegia_ant.frepl  cplegia_ant.inc_revasc  \\\n",
       "0                            1                  2                       2   \n",
       "1                            2                  2                       2   \n",
       "2                            1                  2                       1   \n",
       "3                            1                  2                       2   \n",
       "4                            4                  4                       4   \n",
       "...                        ...                ...                     ...   \n",
       "34556                        2                  2                       2   \n",
       "34557                        2                  2                       2   \n",
       "34558                        4                  4                       4   \n",
       "34559                        2                  2                       2   \n",
       "34560                        4                  4                       4   \n",
       "\n",
       "       cplegia_ret.frepl  cplegia_ret.inc_revasc  frepl.inc_revasc  \n",
       "0                      2                       2                 4  \n",
       "1                      4                       4                 4  \n",
       "2                      2                       1                 2  \n",
       "3                      2                       2                 4  \n",
       "4                      4                       4                 4  \n",
       "...                  ...                     ...               ...  \n",
       "34556                  4                       4                 4  \n",
       "34557                  4                       4                 4  \n",
       "34558                  4                       4                 4  \n",
       "34559                  4                       4                 4  \n",
       "34560                  4                       4                 4  \n",
       "\n",
       "[34561 rows x 15755 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34561, 15756)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = list(feature_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={outcome: 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label: 2 (alive) to 0 (class 0)\n",
    "data.loc[data.label ==2, 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28961\n",
       "1     5600\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train set/test set in stratified fashion, then downsample training set to balance outcome class:\n",
    "from sklearn import model_selection\n",
    "outercv = sklearn.model_selection.StratifiedKFold(n_splits=10,shuffle=True,random_state= 1)\n",
    "X = data.drop(['label'],axis =1).values\n",
    "y = data[['label']].values\n",
    "\n",
    "for train_index, test_index in outercv.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "train_df = data.iloc[train_index]\n",
    "test_df = data.iloc[test_index]\n",
    "train_df_majority = train_df[train_df['label']==0]\n",
    "train_df_minority = train_df[train_df['label']==1]\n",
    "\n",
    "# Downsampling:\n",
    "from sklearn.utils import resample\n",
    "train_df_majority_downsampled = resample(train_df_majority, \n",
    "                                 replace=False,     # sample without replacement\n",
    "                                 n_samples=2*train_df_minority.shape[0],    # to match minority class\n",
    "                                 random_state=1)\n",
    "\n",
    "df_downsampled = pd.concat([train_df_majority_downsampled, train_df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2896],\n",
       "       [   1,  560]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test: 1 = dead, 2 = live. Convert live to class 0:\n",
    "\n",
    "import numpy as np\n",
    "np.array(np.unique(y_test, return_counts=True)).T\n",
    "y_test[y_test == 2] = 0\n",
    "y_train[y_train == 2] = 0\n",
    "np.array(np.unique(y_test, return_counts=True)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set further to cv_train-validation set, using stratified k-fold cv: 10-fold x 5 times\n",
    "# train and calibrate models\n",
    "from sklearn import model_selection\n",
    "outercv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=5, n_repeats = 2,random_state= 1)\n",
    "\n",
    "# initialize:\n",
    "cv_performance_df = pd.DataFrame()\n",
    "cv_performance_isotonic_df = pd.DataFrame()\n",
    "cv_performance_sigmoid_df = pd.DataFrame()\n",
    "training_bs_testset_pred_df = data_full[['concatid',outcome]].loc[test_index,:].rename(columns={outcome: 'label'})\n",
    "training_bs_testset_pred_calibrated_isotonic_df = training_bs_testset_pred_df.copy(deep = True)\n",
    "training_bs_testset_pred_calibrated_sigmoid_df = training_bs_testset_pred_df.copy(deep = True)\n",
    "\n",
    "fold = 1\n",
    "for cv_train_index, cv_test_index in outercv.split(X_train, y_train):\n",
    "    print(\"Fold \"+ str(fold) + \"....\")\n",
    "    fold = fold + 1\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    cv_X_train, cv_X_test = X_train[cv_train_index], X_train[cv_test_index]\n",
    "    cv_y_train, cv_y_test = y_train[cv_train_index], y_train[cv_test_index]\n",
    "    \n",
    "    cv_train_df = data.iloc[cv_train_index]\n",
    "    cv_test_df = data.iloc[cv_test_index]\n",
    "    cv_train_df_majority = cv_train_df[cv_train_df['label']==0]\n",
    "    cv_train_df_minority = cv_train_df[cv_train_df['label']==1]\n",
    "\n",
    "    # Downsampling:\n",
    "    from sklearn.utils import resample\n",
    "    cv_train_df_majority_downsampled = resample(cv_train_df_majority, \n",
    "                                     replace=False,     # sample without replacement\n",
    "                                     n_samples=2*cv_train_df_minority.shape[0],    # to match minority class\n",
    "                                     random_state=1)\n",
    "\n",
    "    # Combine downsampled majority class with minority class\n",
    "    cv_df_downsampled = pd.concat([cv_train_df_majority_downsampled, cv_train_df_minority])\n",
    "    cv_X_train_downsampled = cv_df_downsampled.drop(['label'],axis =1)\n",
    "    cv_y_train_downsampled = cv_df_downsampled['label'].ravel()\n",
    "    \n",
    "    \n",
    "    # Train model:\n",
    "    from catboost import CatBoostClassifier\n",
    "    cv_cb_downsampled =  CatBoostClassifier(random_state = 1)\n",
    "    cv_cb_downsampled.fit(cv_X_train_downsampled, cv_y_train_downsampled, verbose = False)\n",
    "    clear_output()\n",
    "\n",
    "\n",
    "    \n",
    "    # Evaluate model on cv_test_set (validation set):\n",
    "    cv_y_test_predict_proba_cb_downsampled = cv_cb_downsampled.predict_proba(cv_X_test)[:, 1]\n",
    "    performance_metrics = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled, thres = 0.5)\n",
    "    cv_performance_df = cv_performance_df.append(performance_metrics, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Pred prob of model on holdout testset:\n",
    "    training_bs_testset_pred_df['time_'+str(fold-1)] = cv_cb_downsampled.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # calibrate model, record performance metric validation set, and pred prob on holdout testset:\n",
    "    cv_cb_downsampled_isotonic_on_cv = calibrate_model(cv_cb_downsampled, cv_X_train, cv_y_train.ravel(), method = 'isotonic')\n",
    "    clear_output()\n",
    "    training_bs_testset_pred_calibrated_isotonic_df['time_'+str(fold-1)] = cv_cb_downsampled_isotonic_on_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cv_y_test_predict_proba_cb_downsampled_isotonic = cv_cb_downsampled_isotonic_on_cv.predict_proba(cv_X_test)[:, 1]\n",
    "    clear_output()\n",
    "    performance_metrics_isotonic = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled_isotonic, thres = 0.5)\n",
    "    cv_performance_isotonic_df = cv_performance_isotonic_df.append(performance_metrics_isotonic, ignore_index=True)\n",
    "\n",
    "    \n",
    "    cv_cb_downsampled_sigmoid_on_cv = calibrate_model(cv_cb_downsampled, cv_X_train, cv_y_train.ravel(), method = 'sigmoid')\n",
    "    clear_output()\n",
    "\n",
    "    training_bs_testset_pred_calibrated_sigmoid_df['time_'+str(fold-1)] = cv_cb_downsampled_sigmoid_on_cv.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    cv_y_test_predict_proba_cb_downsampled_sigmoid = cv_cb_downsampled_sigmoid_on_cv.predict_proba(cv_X_test)[:, 1]\n",
    "    performance_metrics_sigmoid = performance_wo_figure(cv_y_test, cv_y_test_predict_proba_cb_downsampled_sigmoid, thres = 0.5)\n",
    "    cv_performance_sigmoid_df = cv_performance_sigmoid_df.append(performance_metrics_sigmoid, ignore_index=True)\n",
    "    \n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bs_testset_pred_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_' + outcome +'.csv', index=False)\n",
    "training_bs_testset_pred_calibrated_isotonic_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_isotonic_on_cv_' + outcome +'.csv', index=False)\n",
    "training_bs_testset_pred_calibrated_sigmoid_df.to_csv(load_dir+'/'+'patient_specific_pred_prob_testset_sigmoid_on_cv_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5%</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.723</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5%</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ARC   AUROC   Brier      F1  accuracy  precision  recall    sens  \\\n",
       "count  10.000  10.000  10.000  10.000    10.000     10.000  10.000  10.000   \n",
       "mean    0.720   0.916   0.089   0.677     0.884      0.616   0.752   0.752   \n",
       "std     0.019   0.007   0.003   0.009     0.004      0.012   0.012   0.012   \n",
       "min     0.679   0.900   0.087   0.655     0.874      0.590   0.737   0.737   \n",
       "2.5%    0.686   0.903   0.087   0.659     0.876      0.594   0.738   0.738   \n",
       "50%     0.723   0.917   0.088   0.679     0.885      0.617   0.751   0.751   \n",
       "97.5%   0.749   0.925   0.095   0.686     0.888      0.632   0.774   0.774   \n",
       "max     0.752   0.925   0.096   0.687     0.889      0.634   0.778   0.778   \n",
       "\n",
       "         spec  \n",
       "count  10.000  \n",
       "mean    0.909  \n",
       "std     0.005  \n",
       "min     0.901  \n",
       "2.5%    0.902  \n",
       "50%     0.910  \n",
       "97.5%   0.916  \n",
       "max     0.917  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performance_df.to_csv(load_dir+'/'+'cv_performance_df_' + outcome +'.csv', index=False)\n",
    "cv_performance_df.describe(percentiles = [.025, .5, .975]).round(decimals = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ARC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>F1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.917 (0.903, 0.925)</td>\n",
       "      <td>0.885 (0.876, 0.888)</td>\n",
       "      <td>0.723 (0.686, 0.749)</td>\n",
       "      <td>0.088 (0.087, 0.095)</td>\n",
       "      <td>0.679 (0.659, 0.686)</td>\n",
       "      <td>0.617 (0.594, 0.632)</td>\n",
       "      <td>0.751 (0.738, 0.774)</td>\n",
       "      <td>0.751 (0.738, 0.774)</td>\n",
       "      <td>0.91 (0.902, 0.916)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUROC              accuracy                   ARC  \\\n",
       "0  0.917 (0.903, 0.925)  0.885 (0.876, 0.888)  0.723 (0.686, 0.749)   \n",
       "\n",
       "                  Brier                    F1             precision  \\\n",
       "0  0.088 (0.087, 0.095)  0.679 (0.659, 0.686)  0.617 (0.594, 0.632)   \n",
       "\n",
       "                 recall                  sens                 spec  \n",
       "0  0.751 (0.738, 0.774)  0.751 (0.738, 0.774)  0.91 (0.902, 0.916)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out performance:\n",
    "print_cv_performance = pd.DataFrame(cv_performance_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "\n",
    "print_cv_performance.to_csv(load_dir+'/'+'print_cv_performance_' + outcome +'.csv', index=False)\n",
    "print_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ARC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>F1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856 (0.837, 0.862)</td>\n",
       "      <td>0.867 (0.86, 0.872)</td>\n",
       "      <td>0.58 (0.543, 0.607)</td>\n",
       "      <td>0.097 (0.094, 0.101)</td>\n",
       "      <td>0.42 (0.389, 0.449)</td>\n",
       "      <td>0.725 (0.659, 0.749)</td>\n",
       "      <td>0.299 (0.269, 0.324)</td>\n",
       "      <td>0.299 (0.269, 0.324)</td>\n",
       "      <td>0.977 (0.971, 0.981)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUROC             accuracy                  ARC  \\\n",
       "0  0.856 (0.837, 0.862)  0.867 (0.86, 0.872)  0.58 (0.543, 0.607)   \n",
       "\n",
       "                  Brier                   F1             precision  \\\n",
       "0  0.097 (0.094, 0.101)  0.42 (0.389, 0.449)  0.725 (0.659, 0.749)   \n",
       "\n",
       "                 recall                  sens                  spec  \n",
       "0  0.299 (0.269, 0.324)  0.299 (0.269, 0.324)  0.977 (0.971, 0.981)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performance_isotonic_df.to_csv(load_dir+'/'+'cv_performance_isotonic_df_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_isotonic = pd.DataFrame(cv_performance_isotonic_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_cv_performance_isotonic.to_csv(load_dir+'/'+'print_cv_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ARC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>F1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856 (0.838, 0.863)</td>\n",
       "      <td>0.869 (0.861, 0.874)</td>\n",
       "      <td>0.579 (0.543, 0.606)</td>\n",
       "      <td>0.098 (0.095, 0.103)</td>\n",
       "      <td>0.442 (0.411, 0.478)</td>\n",
       "      <td>0.711 (0.644, 0.728)</td>\n",
       "      <td>0.321 (0.292, 0.356)</td>\n",
       "      <td>0.321 (0.292, 0.356)</td>\n",
       "      <td>0.974 (0.967, 0.977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUROC              accuracy                   ARC  \\\n",
       "0  0.856 (0.838, 0.863)  0.869 (0.861, 0.874)  0.579 (0.543, 0.606)   \n",
       "\n",
       "                  Brier                    F1             precision  \\\n",
       "0  0.098 (0.095, 0.103)  0.442 (0.411, 0.478)  0.711 (0.644, 0.728)   \n",
       "\n",
       "                 recall                  sens                  spec  \n",
       "0  0.321 (0.292, 0.356)  0.321 (0.292, 0.356)  0.974 (0.967, 0.977)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performance_sigmoid_df.to_csv(load_dir+'/'+'cv_performance_sigmoid_df_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_sigmoid = pd.DataFrame(cv_performance_sigmoid_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_cv_performance_sigmoid.to_csv(load_dir+'/'+'print_cv_performance_sigmoid_' + outcome +'.csv', index=False)\n",
    "print_cv_performance_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models:\n",
    "import pickle\n",
    "pickle.dump(cv_cb_downsampled, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled.sav', 'wb'))\n",
    "pickle.dump(cv_cb_downsampled_isotonic_on_cv, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled_isotonic_calibration_on_cv.sav', 'wb'))\n",
    "pickle.dump(cv_cb_downsampled_sigmoid_on_cv, open(work_dir+'/models/pre_anat_intra/'+'model_' +outcome + '_cv_cb_downsampled_isotonic_calibration_on_cv.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>total_importance</th>\n",
       "      <th>min_max_scale_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>status</td>\n",
       "      <td>7.035540</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>5.289334</td>\n",
       "      <td>0.751087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ppef</td>\n",
       "      <td>5.002661</td>\n",
       "      <td>0.710223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfhemoglobin</td>\n",
       "      <td>4.753362</td>\n",
       "      <td>0.674687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>perfustm</td>\n",
       "      <td>4.257457</td>\n",
       "      <td>0.603998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>totalbumin</td>\n",
       "      <td>4.170297</td>\n",
       "      <td>0.591574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pasys</td>\n",
       "      <td>3.884349</td>\n",
       "      <td>0.550813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bmi</td>\n",
       "      <td>3.798635</td>\n",
       "      <td>0.538595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wbc</td>\n",
       "      <td>3.617348</td>\n",
       "      <td>0.512754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creatlst</td>\n",
       "      <td>3.590111</td>\n",
       "      <td>0.508871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature Id  total_importance  min_max_scale_importance\n",
       "1         status          7.035540                  1.000000\n",
       "6            age          5.289334                  0.751087\n",
       "67          ppef          5.002661                  0.710223\n",
       "4   rfhemoglobin          4.753362                  0.674687\n",
       "25      perfustm          4.257457                  0.603998\n",
       "14    totalbumin          4.170297                  0.591574\n",
       "37         pasys          3.884349                  0.550813\n",
       "28           bmi          3.798635                  0.538595\n",
       "24           wbc          3.617348                  0.512754\n",
       "5       creatlst          3.590111                  0.508871"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable Importance:\n",
    "\n",
    "feature_imp_df = cv_cb_downsampled.get_feature_importance(prettified = True)\n",
    "feature_imp_df_sort = feature_imp_df.sort_values(by='Importances', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "feature_imp_df_sort.to_csv(load_dir+'/'+'feature_imp_df_sort_'+outcome+'.csv', index=False)\n",
    "\n",
    "decouple_var_imp_sort = decouple_var_imp(feature_imp_df_sort)\n",
    "decouple_var_imp_sort.to_csv(load_dir+'/'+'decouple_var_imp_sort_'+outcome+'.csv', index=False)\n",
    "decouple_var_imp_sort.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap testset:\n",
    "bs_testset_performance_df = pd.DataFrame()\n",
    "bs_testset_performance_isotonic_df = pd.DataFrame()\n",
    "bs_testset_performance_sigmoid_df = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "    bs_y_test = y_test[sample_indices]\n",
    "    bs_X_test = X_test[sample_indices,:]\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled = cv_cb_downsampled.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled, thres = 0.5)\n",
    "    bs_testset_performance_df = bs_testset_performance_df.append(bs_performance_metrics, ignore_index=True)\n",
    "\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled_isotonic = cv_cb_downsampled_isotonic_on_cv.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics_isotonic = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_isotonic, thres = 0.5)\n",
    "    bs_testset_performance_isotonic_df = bs_testset_performance_isotonic_df.append(bs_performance_metrics_isotonic, ignore_index=True)\n",
    "    \n",
    "    bs_y_test_predict_proba_cb_downsampled_sigmoid = cv_cb_downsampled_sigmoid_on_cv.predict_proba(bs_X_test)[:, 1]\n",
    "    bs_performance_metrics_sigmoid = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_sigmoid, thres = 0.5)\n",
    "    bs_testset_performance_sigmoid_df = bs_testset_performance_sigmoid_df.append(bs_performance_metrics_sigmoid, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_testset_performance_df.to_csv(load_dir+'/'+'bs_testset_performance_df_' + outcome +'.csv', index=False)\n",
    "bs_testset_performance_isotonic_df.to_csv(load_dir+'/'+'bs_testset_performance_isotonic_df_' + outcome +'.csv', index=False)\n",
    "bs_testset_performance_sigmoid_df.to_csv(load_dir+'/'+'bs_testset_performance_sigmoid_df_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_testset_performance_df.describe(percentiles = [.025, .5, .975]).round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance = pd.DataFrame(bs_testset_performance_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance.to_csv(load_dir+'/'+'print_bs_testset_performance_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance_isotonic = pd.DataFrame(bs_testset_performance_isotonic_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance_isotonic.to_csv(load_dir+'/'+'print_bs_testset_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance_isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out performance:\n",
    "print_bs_testset_performance_sigmoid = pd.DataFrame(bs_testset_performance_sigmoid_df[['AUROC', 'accuracy', 'ARC', 'Brier', 'F1','precision','recall', 'sens', 'spec']].apply(lambda x: report_metric(x), axis = 0)).transpose()\n",
    "print_bs_testset_performance_sigmoid.to_csv(load_dir+'/'+'print_bs_testset_performance_isotonic_' + outcome +'.csv', index=False)\n",
    "print_bs_testset_performance_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance figures:\n",
    "performance(bs_y_test, bs_y_test_predict_proba_cb_downsampled, thres = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as plt\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "# ax = feature_imp_df_sort.plot('Feature', 'Score', kind='bar', color='c')\n",
    "# ax.set_title(\"Feature Importance using Permutation method\", fontsize = 14)\n",
    "# ax.set_xlabel(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and calibrate model on entirety of the training set:\n",
    "\n",
    "# X_train_downsampled = df_downsampled.drop(['label'],axis =1)\n",
    "# y_train_downsampled = df_downsampled['label'].ravel()\n",
    "# from catboost import CatBoostClassifier\n",
    "# cb_downsampled =  CatBoostClassifier(random_state = 1)\n",
    "# cb_downsampled.fit(X_train_downsampled, y_train_downsampled, cat_features = np.array(get_cat_features(X_train_downsampled, 5)), verbose = False)\n",
    "# pickle.dump(cb_downsampled, open('model_' +outcome + '_cb_downsampled.sav', 'wb'))\n",
    "\n",
    "# # Create a corrected classifier. - Isotonic calibration\n",
    "# cb_downsampled_iso = sklearn.calibration.CalibratedClassifierCV(cb_downsampled, cv=10, method='isotonic')\n",
    "# cb_downsampled_iso.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "\n",
    "# pickle.dump(cb_downsampled_iso, open('model_' +outcome + '_cb_downsampled_iso.sav', 'wb'))\n",
    "\n",
    "# cb_downsampled_sigmoid = sklearn.calibration.CalibratedClassifierCV(cb_downsampled, cv=10, method='sigmoid')\n",
    "# cb_downsampled_sigmoid.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "# pickle.dump(cb_downsampled_sigmoid, open('model_' +outcome + '_cb_downsampled_sigmoid.sav', 'wb'))\n",
    "\n",
    "# # loaded_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "# # y_test_predict_proba_loaded_model = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # # Bootstrap testset:\n",
    "# # bs_testset_performance_df = pd.DataFrame()\n",
    "# # for i in range(10):\n",
    "# #     sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "# #     bs_y_test = y_test[sample_indices]\n",
    "# #     bs_X_test = X_test[sample_indices,:]\n",
    "# #     bs_y_test_predict_proba_cb_downsampled_iso = cb_downsampled_iso.predict_proba(bs_X_test)[:, 1]\n",
    "# #     bs_performance_metrics = performance(bs_y_test, bs_y_test_predict_proba_cb_downsampled_iso, thres = 0.5)\n",
    "# #     bs_testset_performance_df = bs_testset_performance_df.append(bs_performance_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bootstrap testset and spit prediction using calibrated model:\n",
    "# import pickle\n",
    "# import sklearn\n",
    "# iso_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "\n",
    "# bs_testset_pred_df = pd.DataFrame(list(zip(data_full['concatid'][test_index], test_index)),\n",
    "#                                 columns=['concatid', 'index'])\n",
    "# bs_testset_performance_iso_df = pd.DataFrame()\n",
    "# for i in range(10):\n",
    "#     sample_indices = np.random.randint(len(X_test), size=len(X_test))\n",
    "#     bs_y_test = y_test[sample_indices]\n",
    "#     bs_X_test = X_test[sample_indices,:]\n",
    "#     bs_y_test_predict_proba_cb_downsampled_iso = iso_model.predict_proba(bs_X_test)[:, 1]\n",
    "#     bs_performance_metrics = performance_wo_figure(bs_y_test, bs_y_test_predict_proba_cb_downsampled_iso, thres = 0.5)\n",
    "#     bs_testset_performance_iso_df = bs_testset_performance_iso_df.append(bs_performance_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs_testset_performance_iso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_model = pickle.load(open('model_' +outcome + '_cb_downsampled_iso.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled_iso = iso_model.predict_proba(X_test)[:, 1]\n",
    "# testset_iso_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled_iso)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_iso_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_iso_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_iso_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = before_iso_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_before_iso_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_sigmoid = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='sigmoid')\n",
    "# cv_cb_downsampled_sigmoid.fit(X_train, y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_sigmoid, open('model_' +outcome + '_cv_cb_downsampled_sigmoid.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_sigmoid_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_sigmoid.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_sigmoid_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_sigmoid_' + outcome +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# cv_cb_downsampled_isotonic.fit(X_train, y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic, open('model_' +outcome + '_cv_cb_downsampled_isotonic.sav', 'wb'))\n",
    "# cv_isotonic_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic_on_db = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# X_train_downsampled = df_downsampled.drop(['label'],axis =1)\n",
    "# y_train_downsampled = df_downsampled['label'].ravel()\n",
    "# cv_cb_downsampled_isotonic_on_db.fit(X_train_downsampled, y_train_downsampled.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic_on_db, open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_db.sav', 'wb'))\n",
    "# cv_isotonic_model_on_db = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_db.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model_on_db.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_on_db_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn import calibration\n",
    "# cv_cb_downsampled = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# cv_cb_downsampled_isotonic_on_cv = sklearn.calibration.CalibratedClassifierCV(cv_cb_downsampled, cv=10, method='isotonic')\n",
    "# cv_cb_downsampled_isotonic_on_cv.fit(cv_X_train, cv_y_train.ravel())\n",
    "# pickle.dump(cv_cb_downsampled_isotonic_on_cv, open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_cv.sav', 'wb'))\n",
    "# cv_isotonic_model_on_cv = pickle.load(open('model_' +outcome + '_cv_cb_downsampled_isotonic_on_cv.sav', 'rb'))\n",
    "# y_test_predict_proba_cb_downsampled = cv_isotonic_model_on_cv.predict_proba(X_test)[:, 1]\n",
    "# testset_pred_df = pd.DataFrame(list(zip(y_test, y_test_predict_proba_cb_downsampled)),\n",
    "#                                 columns=['label', 'pred'])\n",
    "# testset_pred_df.to_csv(load_dir+'/'+'pred_prob_testset_isotonic_on_cv_' + outcome +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout testset feature space and sts_pred_prob filter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testset_df = data_full.iloc[test_index,:]\n",
    "# testset_df.to_csv(load_dir+'/'+'testset_feature_df_' + outcome +'.csv', index=True)\n",
    "# # load sts pred prob and filter only patients in the holdout test set:\n",
    "# load_dir = '/home/idies/workspace/Storage/hnguye78/persistent'+'/csv_files'\n",
    "# sts_pred_prob_df = pd.read_csv(load_dir+'/sts_pred_prob.csv')\n",
    "# sts_pred_prob_df['concatid'] = sts_pred_prob_df['patid']+sts_pred_prob_df['recordid']\n",
    "# sts_pred_prob_df_rm_dups = sts_pred_prob_df.drop_duplicates(subset='concatid', keep=\"last\")\n",
    "# sts_pred_prob_testset = sts_pred_prob_df_rm_dups.loc[sts_pred_prob_df_rm_dups['concatid'].isin(testset_df['concatid']),['concatid', 'predvent']]\n",
    "\n",
    "# sts_pred_prob_testset.to_csv(load_dir+'/'+'sts_pred_prob_testset_' + outcome +'.csv', index=False)\n",
    "# # # check to make sure the concatid in sts_pred_prob and in the testset are the same: \n",
    "# print(sorted(list(sts_pred_prob_testset['concatid'])) == sorted(list(testset_df['concatid'])))\n",
    "# # # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Probability of Patients in Non-STS Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dir = '/home/idies/workspace/Storage/hnguye78/persistent'+'/csv_files'\n",
    "# feature_space_non_sts_patients = pd.read_csv(load_dir+'/non_sts_patients_feature_space.csv')\n",
    "# X_non_sts = feature_space_non_sts_patients.drop(['label','Unnamed: 0', 'concatid'], axis = 1).values\n",
    "# import pickle\n",
    "# import sklearn\n",
    "# loaded_model = pickle.load(open('model_' +outcome + '_cv_cb_downsampled.sav', 'rb'))\n",
    "# y_non_sts_predict_proba = loaded_model.predict_proba(X_non_sts)[:, 1]\n",
    "\n",
    "# prob_risk_non_sts_df = pd.DataFrame(list(zip(feature_space_non_sts_patients['concatid'], y_non_sts_predict_proba)),\n",
    "#                                 columns=['concatid', 'predicted_prob'])\n",
    "# prob_risk_non_sts_df.to_csv(load_dir+'/'+'pred_prob_non_sts_patients_df_' + outcome +'.csv', index=False)\n",
    "# # # check to see that the non_sts set does not overlap with the testset concatid \n",
    "# # set((prob_risk_non_sts_df['concatid'])).intersection((set(testset_df['concatid'])))\n",
    "# # # no overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
